people <- people %>%
mutate(Initials = paste(FirstInitial, LastInitial))
print(people)
# Purpose: Add a new column "Initials" by extracting the first letter of each name.
# Step 1: Create a dataframe with columns "FirstName" and "LastName"
library(dplyr)
people <- data.frame(
FirstName = c("John", "Jane", "Mike", "Sara"),
LastName = c("Doe", "Smith", "Johnson", "Lee")
)
# Step 2a: Extract the first letter of "FirstName" and "LastName"
people <- people %>%
mutate(FirstInitial = substr(FirstName, 1, 1),  # Extract first letter of first name
LastInitial = substr(LastName, 1, 1))    # Extract first letter of last name
print (people)
# Step 2b: Combine the initials into a single "Initials" column
people <- people %>%
mutate(Initials = paste(FirstInitial, LastInitial))
print(people)
# Step 4: Print the final dataset
display(people)
########################################################################
# Problem (It is not necessary to include this in your code file for the
# final project. However, this is a crucial phase and should be included
# in your presentation deck. I mention it here to emphasize its relevance
# and importance in the process.)
########################################################################
# Problem Statement:
# Zillow, a major player in real estate, has recently come under scrutiny due
# to significant fluctuations in housing prices in various regions, particularly
# in response to external factors like rising interest rates and inflation. These
# fluctuations have raised concerns about the accuracy of Zillow’s price prediction models,
# particularly their ability to provide reliable estimates for homes listed on the
# platform. Zillow’s leadership team has tasked the analytics team with analyzing
# historical housing data to understand the root causes of pricing inaccuracies and
# propose improvements to the pricing prediction model.
# Key Questions:
# How accurate are Zillow's current price predictions compared to actual selling prices?
#  --Code/Analysis Connection: Use the model's RMSE and R-squared to evaluate prediction performance.
# Which factors (e.g., area, number of bedrooms, bathrooms, etc.) have the most significant impact on price prediction errors?
#  --Code/Analysis Connection: Analyze the coefficients of the multiple regression model to determine which variables contribute most to price prediction.
# Are there any patterns of over- or under-prediction in specific areas or home types?
#  --Code/Analysis Connection: Visualize the residuals (prediction errors) to detect any bias or patterns.
# Do any model assumptions (e.g., linearity, multicollinearity) need to be addressed to improve prediction accuracy?
#  --Code/Analysis Connection: Use residual plots, VIF, and Q-Q plots to check for assumptions and model diagnostics.
# How can Zillow’s pricing algorithm be improved to adapt to current market volatility?
#  -- Code/Analysis Connection: Based on the insights gained from the analysis, explore alternative models (e.g., regularization techniques) to improve the model's robustness.
# Root Cause Analysis:
# 1. Why are Zillow’s pricing predictions sometimes inaccurate?
#    Because the model does not account for all market conditions (e.g., sudden interest rate hikes, regional demand fluctuations).
### 2. Why doesn't the model account for these market conditions?
###    The current variables in the model (e.g., area, number of bedrooms, etc.) are not sufficient to capture dynamic market factors like economic shifts or buyer sentiment.
##### 3. Why weren’t more dynamic factors included in the model?
#####    Zillow’s initial model was built based on static historical data, without incorporating real-time data or external economic indicators.
####### 4. Why is the model dependent on static historical data?
#######    The original algorithm was designed with a focus on past trends rather than adaptive mechanisms that can adjust based on changing market conditions.
######### 5. Why hasn’t the model been updated to include adaptive features?
#########    The decision to update the model has been delayed due to the complexity of incorporating real-time data and the cost of implementing new algorithms.
########################################################################
########################################################################
# DATA
########################################################################
########################################################################
########################################################################
# Data Loading and Cleaning
########################################################################
# This code loads necessary libraries, imports a dataset, and performs basic
# data cleaning.
#
# How it works:
# 1. Load Libraries:
#    - Essential libraries for data manipulation, visualization, and model
#      evaluation (`caret`, `car`, `dplyr`, `GGally`, `ggplot2`, `readr`, `tidyr`).
# 2. Load Dataset:
#    - Reads the "Housing.csv" file using `read_csv()`.
#    - Displays dataset structure with `head()`, `str()`, and `summary()`.
# 3. Data Cleaning:
#    - Replaces empty strings with `NA`.
#    - Imputes missing numeric values with the median.
#    - Removes duplicate rows using `distinct()`.
# Why it's important:
# Loading libraries and cleaning data ensures a prepared dataset for analysis,
# improving accuracy and integrity.
# Load necessary libraries
library(caret)    # For splitting the dataset and evaluating the model
library(car)      # For VIF and other regression diagnostics
library(dplyr)    # For data manipulation
library(GGally)   # For creating advanced scatter plot matrices and correlation plots
library(ggplot2)  # For visualizations
library(readr)    # For reading CSV files
library(tidyr)    # For reshaping and tidying data (e.g., pivoting data frames)
# Load the dataset
dataset <- read_csv("Housing.csv")
setwd("~/Documents/GitHub/BUAN348-448/Weeks 4-5")
########################################################################
# Problem (It is not necessary to include this in your code file for the
# final project. However, this is a crucial phase and should be included
# in your presentation deck. I mention it here to emphasize its relevance
# and importance in the process.)
########################################################################
# Problem Statement:
# Zillow, a major player in real estate, has recently come under scrutiny due
# to significant fluctuations in housing prices in various regions, particularly
# in response to external factors like rising interest rates and inflation. These
# fluctuations have raised concerns about the accuracy of Zillow’s price prediction models,
# particularly their ability to provide reliable estimates for homes listed on the
# platform. Zillow’s leadership team has tasked the analytics team with analyzing
# historical housing data to understand the root causes of pricing inaccuracies and
# propose improvements to the pricing prediction model.
# Key Questions:
# How accurate are Zillow's current price predictions compared to actual selling prices?
#  --Code/Analysis Connection: Use the model's RMSE and R-squared to evaluate prediction performance.
# Which factors (e.g., area, number of bedrooms, bathrooms, etc.) have the most significant impact on price prediction errors?
#  --Code/Analysis Connection: Analyze the coefficients of the multiple regression model to determine which variables contribute most to price prediction.
# Are there any patterns of over- or under-prediction in specific areas or home types?
#  --Code/Analysis Connection: Visualize the residuals (prediction errors) to detect any bias or patterns.
# Do any model assumptions (e.g., linearity, multicollinearity) need to be addressed to improve prediction accuracy?
#  --Code/Analysis Connection: Use residual plots, VIF, and Q-Q plots to check for assumptions and model diagnostics.
# How can Zillow’s pricing algorithm be improved to adapt to current market volatility?
#  -- Code/Analysis Connection: Based on the insights gained from the analysis, explore alternative models (e.g., regularization techniques) to improve the model's robustness.
# Root Cause Analysis:
# 1. Why are Zillow’s pricing predictions sometimes inaccurate?
#    Because the model does not account for all market conditions (e.g., sudden interest rate hikes, regional demand fluctuations).
### 2. Why doesn't the model account for these market conditions?
###    The current variables in the model (e.g., area, number of bedrooms, etc.) are not sufficient to capture dynamic market factors like economic shifts or buyer sentiment.
##### 3. Why weren’t more dynamic factors included in the model?
#####    Zillow’s initial model was built based on static historical data, without incorporating real-time data or external economic indicators.
####### 4. Why is the model dependent on static historical data?
#######    The original algorithm was designed with a focus on past trends rather than adaptive mechanisms that can adjust based on changing market conditions.
######### 5. Why hasn’t the model been updated to include adaptive features?
#########    The decision to update the model has been delayed due to the complexity of incorporating real-time data and the cost of implementing new algorithms.
########################################################################
########################################################################
# DATA
########################################################################
########################################################################
########################################################################
# Data Loading and Cleaning
########################################################################
# This code loads necessary libraries, imports a dataset, and performs basic
# data cleaning.
#
# How it works:
# 1. Load Libraries:
#    - Essential libraries for data manipulation, visualization, and model
#      evaluation (`caret`, `car`, `dplyr`, `GGally`, `ggplot2`, `readr`, `tidyr`).
# 2. Load Dataset:
#    - Reads the "Housing.csv" file using `read_csv()`.
#    - Displays dataset structure with `head()`, `str()`, and `summary()`.
# 3. Data Cleaning:
#    - Replaces empty strings with `NA`.
#    - Imputes missing numeric values with the median.
#    - Removes duplicate rows using `distinct()`.
# Why it's important:
# Loading libraries and cleaning data ensures a prepared dataset for analysis,
# improving accuracy and integrity.
# Load necessary libraries
library(caret)    # For splitting the dataset and evaluating the model
library(car)      # For VIF and other regression diagnostics
library(dplyr)    # For data manipulation
library(GGally)   # For creating advanced scatter plot matrices and correlation plots
library(ggplot2)  # For visualizations
library(readr)    # For reading CSV files
library(tidyr)    # For reshaping and tidying data (e.g., pivoting data frames)
# Load the dataset
dataset <- read_csv("Housing.csv")
head(dataset)
str(dataset)
summary(dataset)
# Data Cleaning
# Replace missing values (if any) with NA
dataset[dataset == ""] <- NA
# Impute missing numeric variables with the median
numeric_cols <- sapply(dataset, is.numeric)
dataset[numeric_cols] <- lapply(dataset[numeric_cols], function(x) {
ifelse(is.na(x), median(x, na.rm = TRUE), x)
})
# Check for duplicate rows and remove them
dataset <- dataset %>% distinct()
print(dataset)
print(dataset)
print(dataset)
########################################################################
# Handling Categorical Variables
########################################################################
# This code converts categorical variables in the dataset into factors.
#
# How it works:
# - Uses `mutate()` to convert specified columns into factor types.
# - Defines levels for each factor to represent categories (e.g., "no", "yes").
# - Ensures categorical variables are correctly handled in analysis and modeling.
# Why it's important:
# Converting categorical variables to factors ensures they are treated appropriately
# in statistical analyses and machine learning models.
# Convert categorical variables to factors
dataset <- dataset %>%
mutate(
mainroad = factor(mainroad, levels = c("no", "yes")),
guestroom = factor(guestroom, levels = c("no", "yes")),
basement = factor(basement, levels = c("no", "yes")),
hotwaterheating = factor(hotwaterheating, levels = c("no", "yes")),
airconditioning = factor(airconditioning, levels = c("no", "yes")),
prefarea = factor(prefarea, levels = c("no", "yes")),
furnishingstatus = factor(furnishingstatus, levels = c("unfurnished", "semi-furnished", "furnished"))
)
# # Apply one-hot encoding using dummyVars from the caret package
# dummies_model <- dummyVars(~ ., data = dataset)
# dataset_one_hot <- predict(dummies_model, newdata = dataset)
#
# # Convert the result to a data frame
# dataset_one_hot <- as.data.frame(dataset_one_hot)
#
# # Print the one-hot encoded dataset
# print(dataset_one_hot)
# Data Visualization (Box plot, Scatter plot matrix, Heatmap)
# Box plot for numeric variables
numeric_columns <- dataset %>% select(area, bedrooms, bathrooms, stories, parking, price)
numeric_columns_long <- numeric_columns %>%
pivot_longer(cols = -price, names_to = "variable", values_to = "value")
print(numeric_columns_long)
ggplot(numeric_columns_long, aes(x = variable, y = value)) +
geom_boxplot() +
ggtitle('Box Plot of Numeric Variables') +
xlab('Variables') +
ylab('Values') +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
facet_wrap(~variable, scales = "free_y")
# Scatter plot matrix
ggpairs(dataset %>% select(area, bedrooms, bathrooms, stories, parking, price),
title = "Scatter Plot Matrix of Selected Variables")
# Correlation heatmap
correlation_matrix <- cor(dataset %>% select_if(is.numeric))
melted_corr_matrix <- as.data.frame(as.table(correlation_matrix))
ggplot(data = melted_corr_matrix, aes(x = Var1, y = Var2, fill = Freq)) +
geom_tile() +
geom_text(aes(label = round(Freq, 2)), color = "black", size = 4) +  # Add correlation values
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1, 1), space = "Lab",
name = "Correlation") +
theme_minimal() +
ggtitle("Correlation Heatmap of Numeric Variables") +
xlab("Variables") +
ylab("Variables") +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
# Split the dataset into training and testing sets
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(dataset$price, p = 0.8, list = FALSE)
train_data <- dataset[trainIndex, ]
test_data <- dataset[-trainIndex, ]
# Fit the Multiple Linear Regression Model
model <- lm(price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom + basement +
hotwaterheating + airconditioning + parking + prefarea + furnishingstatus, data = train_data)
# Model Summary
summary(model)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data)
# Evaluate Model Performance
# Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)
actual_values <- test_data$price
mse <- mean((actual_values - predictions)^2)
rmse <- sqrt(mse)
cat("Mean Squared Error (MSE): ", mse, "\n")
cat("Root Mean Squared Error (RMSE): ", rmse, "\n")
# R-squared and Adjusted R-squared
r_squared <- summary(model)$r.squared
adjusted_r_squared <- summary(model)$adj.r.squared
cat("R-squared: ", r_squared, "\n")
cat("Adjusted R-squared: ", adjusted_r_squared, "\n")
########################################################################
########################################################################
# ADVANCED CONCEPTS
########################################################################
########################################################################
########################################################################
# Regularization with Ridge, Lasso, and Elastic Net
########################################################################
# This code demonstrates regularization techniques (Ridge, Lasso, and Elastic Net)
# for linear regression models to prevent overfitting and improve model performance.
#
# How it works:
# 1. Data Preparation: `model.matrix()` is used to convert the training and test datasets
#    into matrices required by the `glmnet` package. The predictor variables are specified,
#    and the target variable is extracted separately.
# 2. Ridge Regression:
#    - Ridge regression adds a penalty to the regression coefficients to shrink them.
#    - It uses the `cv.glmnet()` function with `alpha = 0` to perform cross-validated Ridge regression.
#    - Predictions are made using the best lambda value found during cross-validation.
#    - The Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are computed to evaluate performance.
# 3. Lasso Regression:
#    - Lasso regression also adds a penalty but can set some coefficients to zero, effectively performing
#      variable selection.
#    - It is performed using `cv.glmnet()` with `alpha = 1`.
#    - Predictions, MSE, and RMSE are calculated similarly to Ridge.
# 4. Elastic Net Regression:
#    - Elastic Net combines Ridge and Lasso penalties and is controlled by the `alpha` parameter (0 < alpha < 1).
#    - It is executed with `alpha = 0.5`, balancing between Ridge and Lasso regularization.
#    - Predictions, MSE, and RMSE are calculated similarly to the other models.
# 5. Model Comparison:
#    - The code prints the MSE and RMSE for each regularization method.
#    - A summary table (`model_comparison`) compares the performance of linear regression, Ridge, Lasso,
#      and Elastic Net models in terms of MSE, RMSE, R-squared, and Adjusted R-squared.
#
# Why it's important:
# Regularization techniques like Ridge, Lasso, and Elastic Net are crucial for handling multicollinearity and
# preventing overfitting in linear regression models, especially when dealing with a large number of predictors.
# These methods enhance the model's ability to generalize to new data, leading to more accurate and robust predictions.
library(glmnet)
# Prepare data for glmnet (it requires a matrix of predictors)
x_train <- model.matrix(price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom + basement +
hotwaterheating + airconditioning + parking + prefarea + furnishingstatus, data = train_data)[, -1]
y_train <- train_data$price
x_test <- model.matrix(price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom + basement +
hotwaterheating + airconditioning + parking + prefarea + furnishingstatus, data = test_data)[, -1]
y_test <- test_data$price
# Ridge Regression
ridge_model <- cv.glmnet(x_train, y_train, alpha = 0)  # alpha = 0 for Ridge
ridge_predictions <- predict(ridge_model, s = ridge_model$lambda.min, newx = x_test)
ridge_mse <- mean((ridge_predictions - y_test)^2)
ridge_rmse <- sqrt(ridge_mse)
# Lasso Regression
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1)  # alpha = 1 for Lasso
lasso_predictions <- predict(lasso_model, s = lasso_model$lambda.min, newx = x_test)
lasso_mse <- mean((lasso_predictions - y_test)^2)
lasso_rmse <- sqrt(lasso_mse)
# Elastic Net Regression
elasticnet_model <- cv.glmnet(x_train, y_train, alpha = 0.5)  # alpha = 0.5 for Elastic Net
elasticnet_predictions <- predict(elasticnet_model, s = elasticnet_model$lambda.min, newx = x_test)
elasticnet_mse <- mean((elasticnet_predictions - y_test)^2)
elasticnet_rmse <- sqrt(elasticnet_mse)
# Output key metrics for each model
cat("Ridge MSE: ", ridge_mse, "\nRidge RMSE: ", ridge_rmse, "\n")
cat("Lasso MSE: ", lasso_mse, "\nLasso RMSE: ", lasso_rmse, "\n")
cat("Elastic Net MSE: ", elasticnet_mse, "\nElastic Net RMSE: ", elasticnet_rmse, "\n")
# Summary of all models' performance for comparison
# Collect all model metrics
model_comparison <- data.frame(
Model = c("Linear Regression", "Ridge Regression", "Lasso Regression", "Elastic Net Regression"),
MSE = c(mse, ridge_mse, lasso_mse, elasticnet_mse),
RMSE = c(rmse, ridge_rmse, lasso_rmse, elasticnet_rmse),
R_squared = c(r_squared, NA, NA, NA),  # R-squared only applies to linear regression
Adjusted_R_squared = c(adjusted_r_squared, NA, NA, NA)  # Adjusted R-squared only applies to linear regression
)
# Display the comparison of models
print(model_comparison)
#######################################################################
# Outlier Removal with IQR
#######################################################################
# This function removes outliers from a dataset based on the Interquartile
# Range (IQR) for specified numeric columns.
#
# How it works:
# 1. For each column in the provided list of columns, the function calculates
#    the first quartile (Q1) and the third quartile (Q3).
# 2. The IQR is computed as the difference between Q3 and Q1.
# 3. The lower bound and upper bound for outliers are calculated as Q1 - 1.5 * IQR
#    and Q3 + 1.5 * IQR, respectively.
# 4. Rows in the dataset where the column values fall outside these bounds are
#    considered outliers and are removed.
# 5. The function returns the cleaned dataset without these outliers.
#
# Why it's important:
# Outliers can significantly affect statistical analyses and machine learning models
# by skewing results and reducing model performance. Removing outliers ensures that
# the data is more representative of the typical patterns, leading to more accurate
# insights and predictions.
# Remove outliers based on IQR for selected numeric columns
remove_outliers <- function(data, cols) {
for (col in cols) {
Q1 <- quantile(data[[col]], 0.25)
Q3 <- quantile(data[[col]], 0.75)
IQR_value <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value
# Filter the dataset to remove outliers
data <- data %>%
filter(data[[col]] >= lower_bound & data[[col]] <= upper_bound)
}
return(data)
}
# List of numeric columns to check for outliers
numeric_columns <- c('area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'price')
# Apply the function to remove outliers
dataset_clean <- remove_outliers(dataset, numeric_columns)
# Check the data after outlier removal
summary(dataset_clean)
########################################################################
# Assumptions of Multiple Linear Regression
########################################################################
# This code provides data visualizations and statistical tests to check
# if the assumptions of Multiple Linear Regression (MLR) are met.
#
# How it works:
# 1. Linearity:
#    - A scatter plot is created to visualize the relationship between the
#      actual and predicted values of the target variable.
#    - The plot includes a red diagonal line representing perfect predictions.
#    - If points are scattered around the red line without a clear pattern,
#      the assumption of linearity is likely met.
#
# 2. Homoscedasticity:
#    - A residual plot is generated to check for homoscedasticity, which means
#      the residuals (errors) should have constant variance across fitted values.
#    - The residuals are plotted against the fitted values, with a smooth line
#      (in red) added to visualize trends.
#    - If the residuals are randomly scattered around the horizontal axis,
#      homoscedasticity is likely satisfied.
#
# 3. Normality of Residuals:
#    - A Q-Q plot is used to check if the residuals follow a normal distribution.
#    - The points in the Q-Q plot should lie approximately along the reference
#      line. Deviations from this line suggest non-normality of residuals.
#
# 4. Independence:
#    - The Durbin-Watson test is performed to check for autocorrelation in the
#      residuals, which indicates if the residuals are independent.
#    - A Durbin-Watson statistic around 2 suggests that there is no significant
#      autocorrelation.
#
# 5. Multicollinearity:
#    - Variance Inflation Factor (VIF) values are calculated for each predictor
#      in the model.
#    - High VIF values (typically above 5 or 10) indicate multicollinearity,
#      meaning that some predictors are highly correlated with each other,
#      which can affect the stability of the regression coefficients.
#
# Why it's important:
# Checking MLR assumptions is critical to ensure the validity and reliability
# of the regression results. Violations of these assumptions can lead to
# misleading inferences, incorrect predictions, and unreliable model performance.
# Proper diagnostics and visualizations help identify and address potential
# issues, improving the model's overall robustness.
# Data Visualizations/Results for MLR Assumptions
# Linearity (scatter plot of actual vs predicted values)
ggplot(test_data, aes(x = predictions, y = actual_values)) +
geom_point(color = 'blue') +
geom_abline(slope = 1, intercept = 0, color = 'red') +
ggtitle('Actual vs Predicted Prices') +
xlab('Predicted Prices') +
ylab('Actual Prices')
# Homoscedasticity (residual plot)
residuals_data <- data.frame(fitted_values = fitted(model), residuals = resid(model))
ggplot(residuals_data, aes(x = fitted_values, y = residuals)) +
geom_point() +
geom_smooth(method = 'loess', color = 'red') +
ggtitle('Residuals vs Fitted Values') +
xlab('Fitted Values') +
ylab('Residuals')
# Normality of Residuals (Q-Q plot)
ggplot(residuals_data, aes(sample = residuals)) +
stat_qq() +
stat_qq_line() +
ggtitle('Q-Q Plot of Residuals')
# Independence
# Perform the Durbin-Watson test
durbinWatsonTest(model)
# Multicollinearity (VIF)
vif_values <- vif(model)
print(vif_values)
########################################################################
# Cross-Validation
########################################################################
# This code sets up and performs cross-validation for a Multiple Linear
# Regression model.
#
# How it works:
# 1. `trainControl()` is used to define the cross-validation method. Here,
#    10-fold cross-validation is specified, meaning the dataset will be split
#    into 10 parts. The model is trained on 9 parts and tested on the remaining
#    part, repeating this process 10 times.
# 2. `train()` is then used to fit the Multiple Linear Regression model.
#    The model formula (`price ~ ...`) specifies that 'price' is the dependent
#    variable, and the other columns are independent variables.
# 3. The `trControl` argument links the cross-validation settings to the
#    model training process.
# 4. After training, the `summary()` function provides a detailed summary
#    of the fitted model, showing coefficients and statistical metrics.
# 5. The cross-validation results, including the Root Mean Squared Error (RMSE)
#    and R-squared values, are printed to evaluate model performance.
#
# Why it's important:
# Cross-validation is a key technique to assess the performance and generalization
# ability of a model. It provides a more robust estimate of how the model will
# perform on unseen data, helping to prevent overfitting and ensuring that the
# model's predictions are reliable when applied to new datasets.
# Set up cross-validation
train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation
# Fit the Multiple Linear Regression Model with cross-validation
model <- train(
price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom + basement +
hotwaterheating + airconditioning + parking + prefarea + furnishingstatus,
data = dataset,
method = "lm",
trControl = train_control
)
# View model summary
summary(model)
# Evaluate model performance using cross-validation results
cat("Cross-validated RMSE: ", model$results$RMSE, "\n")
cat("Cross-validated R-squared: ", model$results$Rsquared, "\n")
########################################################################
########################################################################
# IMPACT (It is not necessary to include this in your code file for the
# final project. However, this is a crucial phase and should be included
# in your presentation deck. I mention it here to emphasize its relevance
# and importance in the process.)
########################################################################
########################################################################
# Go back to the mini case and focus on answering the questions. Share your
# findings and provide a managerial recommendation. Two sentences should
# suffice for each. "We find..." and "Therefore, we suggest..." Try to
# connect some part of the managerial recommendation to your 5 Whys drivers.
# Once complete, we will debrief this mini case as a group.
